{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TimeComparison.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZzDjkGnuOCN"
      },
      "source": [
        "# Training time comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuaelYx9vuHZ"
      },
      "source": [
        "We consider the training time as the average time of the last five (out of six) training epochs since the first is usually longer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgmMIBA-BTGi"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "from tensorflow.keras import datasets, models \n",
        "from tensorflow.keras import layers, activations, initializers, regularizers\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "from functools import partial\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.python.ops import variables as tf_variables"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVhb5L0CBS_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855bf7a6-910b-443e-d715-42a14772f118"
      },
      "source": [
        "(Xtr_cifar, ytr_cifar), (Xte_cifar, yte_cifar) = cifar10.load_data()\n",
        "Xtr_cifar = Xtr_cifar / 255\n",
        "Xte_cifar = Xte_cifar / 255\n",
        "\n",
        "Xtr_cifar -= np.mean(Xtr_cifar, axis=0)\n",
        "Xte_cifar -= np.mean(Xtr_cifar, axis=0)\n",
        "\n",
        "n_classes = 10\n",
        "ytr_cifar = kr.utils.to_categorical(ytr_cifar, num_classes=n_classes)\n",
        "yte_cifar = kr.utils.to_categorical(yte_cifar, num_classes=n_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0XAPG2VMQd5"
      },
      "source": [
        "def learning_rate(epoch):\n",
        "    lr = 1e-2\n",
        "    return lr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnUcKTtfQKzY"
      },
      "source": [
        "lr_scheduler = LearningRateScheduler(learning_rate)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "callbacks = [lr_reducer,lr_scheduler]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ZBC4THuh1t"
      },
      "source": [
        "## Real Valued CNN with similar architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R45bUZdOf451"
      },
      "source": [
        "DefaultConv2D = partial(kr.layers.Conv2D, \n",
        "                        kernel_size=3, \n",
        "                        strides=1, \n",
        "                        padding=\"SAME\", \n",
        "                        use_bias=False, \n",
        "                        kernel_initializer='he_uniform',\n",
        "                        kernel_regularizer=kr.regularizers.l2(1e-3))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNSyIEbxlMvf"
      },
      "source": [
        "class ResidualUnit(kr.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, conv_first=True, activation=\"elu\", include_bn=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = kr.activations.get(activation)\n",
        "        self.conv_first = conv_first\n",
        "        self.include_bn = include_bn\n",
        "\n",
        "        self.main_layers = []\n",
        "        if self.conv_first:\n",
        "            self.main_layers.append(DefaultConv2D(filters, strides=strides))\n",
        "            if self.include_bn:\n",
        "                self.main_layers.append(kr.layers.BatchNormalization())\n",
        "            self.main_layers.append(self.activation)\n",
        "            self.main_layers.append(DefaultConv2D(filters))\n",
        "            if self.include_bn:\n",
        "                self.main_layers.append(kr.layers.BatchNormalization())\n",
        "        else:\n",
        "            if self.include_bn:\n",
        "                self.main_layers.append(kr.layers.BatchNormalization())\n",
        "            self.main_layers.append(self.activation)\n",
        "            self.main_layers.append(DefaultConv2D(filters, strides=strides))\n",
        "            if self.include_bn:\n",
        "                self.main_layers.append(kr.layers.BatchNormalization())\n",
        "            self.main_layers.append(self.activation)\n",
        "            self.main_layers.append(DefaultConv2D(filters))\n",
        "\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [DefaultConv2D(filters, kernel_size=1, strides=strides)]\n",
        "            if self.include_bn:\n",
        "                self.skip_layers.append(kr.layers.BatchNormalization())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        if self.conv_first:\n",
        "            return self.activation(Z + skip_Z)\n",
        "        else:\n",
        "            return Z + skip_Z"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4KQYxepluil"
      },
      "source": [
        "model = kr.models.Sequential()\n",
        "model.add(DefaultConv2D(24, kernel_size=3, strides=1,\n",
        "                        input_shape=[32, 32, 3]))\n",
        "prev_filters = 24\n",
        "for filters in [24] * 3 + [48] * 2 + [96] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "model.add(kr.layers.GlobalAvgPool2D())\n",
        "model.add(kr.layers.Flatten())\n",
        "model.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UPd0GhPmxCi",
        "outputId": "bec2be82-8762-48b8-e90f-a15bb1b48234"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 24)        648       \n",
            "_________________________________________________________________\n",
            "residual_unit (ResidualUnit) (None, 32, 32, 24)        10560     \n",
            "_________________________________________________________________\n",
            "residual_unit_1 (ResidualUni (None, 32, 32, 24)        10560     \n",
            "_________________________________________________________________\n",
            "residual_unit_2 (ResidualUni (None, 32, 32, 24)        10560     \n",
            "_________________________________________________________________\n",
            "residual_unit_3 (ResidualUni (None, 16, 16, 48)        32832     \n",
            "_________________________________________________________________\n",
            "residual_unit_4 (ResidualUni (None, 16, 16, 48)        41856     \n",
            "_________________________________________________________________\n",
            "residual_unit_5 (ResidualUni (None, 8, 8, 96)          130176    \n",
            "_________________________________________________________________\n",
            "residual_unit_6 (ResidualUni (None, 8, 8, 96)          166656    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 404,818\n",
            "Trainable params: 403,090\n",
            "Non-trainable params: 1,728\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16uSTnmyE-wW"
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(width_shift_range=0.125, height_shift_range=0.125, horizontal_flip=True)\n",
        "datagen.fit(Xtr_cifar)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxKb6ocBIsl8",
        "outputId": "9b5b2922-3b42-4579-c709-28447a0d0614"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "model.fit(datagen.flow(Xtr_cifar, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_cifar,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 47s 75ms/step - loss: 3.5432 - accuracy: 0.3480 - val_loss: 4.7486 - val_accuracy: 0.1272\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 3.3054 - accuracy: 0.4278 - val_loss: 4.2538 - val_accuracy: 0.1868\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 3.1872 - accuracy: 0.4621 - val_loss: 4.0625 - val_accuracy: 0.2154\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 28s 71ms/step - loss: 3.0881 - accuracy: 0.4917 - val_loss: 3.6939 - val_accuracy: 0.3140\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 3.0035 - accuracy: 0.5148 - val_loss: 3.6445 - val_accuracy: 0.2854\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 27s 70ms/step - loss: 2.9259 - accuracy: 0.5342 - val_loss: 4.0560 - val_accuracy: 0.2530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea5040a690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ9VzMX5ztLi"
      },
      "source": [
        "Average time is 29s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8O7k1G8rk6z"
      },
      "source": [
        "## Real Valued CNN with similar number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nHSxq9frxMi"
      },
      "source": [
        "model = kr.models.Sequential()\n",
        "model.add(DefaultConv2D(12, kernel_size=3, strides=1,\n",
        "                        input_shape=[32, 32, 3]))\n",
        "prev_filters = 12\n",
        "for filters in [12] * 3 + [24] * 2 + [48] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    model.add(ResidualUnit(filters, strides=strides))\n",
        "    prev_filters = filters\n",
        "model.add(kr.layers.GlobalAvgPool2D())\n",
        "model.add(kr.layers.Flatten())\n",
        "model.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd5CZbrdrrKC",
        "outputId": "16d4d45f-f5f0-4ac5-ed94-ee627bb325f1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 12)        324       \n",
            "_________________________________________________________________\n",
            "residual_unit_7 (ResidualUni (None, 32, 32, 12)        2688      \n",
            "_________________________________________________________________\n",
            "residual_unit_8 (ResidualUni (None, 32, 32, 12)        2688      \n",
            "_________________________________________________________________\n",
            "residual_unit_9 (ResidualUni (None, 32, 32, 12)        2688      \n",
            "_________________________________________________________________\n",
            "residual_unit_10 (ResidualUn (None, 16, 16, 24)        8352      \n",
            "_________________________________________________________________\n",
            "residual_unit_11 (ResidualUn (None, 16, 16, 24)        10560     \n",
            "_________________________________________________________________\n",
            "residual_unit_12 (ResidualUn (None, 8, 8, 48)          32832     \n",
            "_________________________________________________________________\n",
            "residual_unit_13 (ResidualUn (None, 8, 8, 48)          41856     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                490       \n",
            "=================================================================\n",
            "Total params: 102,478\n",
            "Trainable params: 101,614\n",
            "Non-trainable params: 864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5FrR9yOrrC5",
        "outputId": "0fc93530-01b6-4863-b3ff-b313249f5517"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "model.fit(datagen.flow(Xtr_cifar, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_cifar,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 31s 74ms/step - loss: 2.8254 - accuracy: 0.2834 - val_loss: 2.8598 - val_accuracy: 0.2279\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 2.5760 - accuracy: 0.3797 - val_loss: 3.0404 - val_accuracy: 0.1744\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 28s 71ms/step - loss: 2.4646 - accuracy: 0.4190 - val_loss: 3.1251 - val_accuracy: 0.1775\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 27s 69ms/step - loss: 2.3778 - accuracy: 0.4434 - val_loss: 2.6220 - val_accuracy: 0.3176\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 2.3056 - accuracy: 0.4649 - val_loss: 3.4944 - val_accuracy: 0.1455\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 2.2431 - accuracy: 0.4849 - val_loss: 3.1335 - val_accuracy: 0.2257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9f2557cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCG9pglC05v0"
      },
      "source": [
        "Average time is 28s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciUWqg-3uALi"
      },
      "source": [
        "## Tessarine Valued CNN with Hypercomplex Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiPPfWnNkbs-"
      },
      "source": [
        "def _compute_fans(shape):\n",
        "    \"\"\"Computes the number of input and output units for a weight shape.\n",
        "    Args:\n",
        "        shape: Integer shape tuple or TF tensor shape.\n",
        "    Returns:\n",
        "        A tuple of integer scalars (fan_in, fan_out).\n",
        "\n",
        "    Extracted from tensorflow/keras/initializers. Available at\n",
        "    https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/keras/initializers/initializers_v2.py\n",
        "    \"\"\"\n",
        "\n",
        "    if len(shape) < 1:  # Just to avoid errors for constants.\n",
        "        fan_in = fan_out = 1\n",
        "    elif len(shape) == 1:\n",
        "        fan_in = fan_out = shape[0]\n",
        "    elif len(shape) == 2:\n",
        "        fan_in = shape[0]\n",
        "        fan_out = shape[1]\n",
        "    else:\n",
        "        # Assuming convolution kernels (2D, 3D, or more).\n",
        "        # kernel shape: (..., input_depth, depth)\n",
        "        receptive_field_size = 1\n",
        "        for dim in shape[:-2]:\n",
        "            receptive_field_size *= dim\n",
        "        fan_in = shape[-2] * receptive_field_size\n",
        "        fan_out = shape[-1] * receptive_field_size\n",
        "    return int(fan_in), int(fan_out)\n",
        "\n",
        "\n",
        "class Hypercomplex4DInitializer(initializers.Initializer):\n",
        "    \"\"\"\n",
        "    Computes initialization based on quaternion variance.\n",
        "    Options: he uniform, he normal, glorot uniform, glorot normal.\n",
        "    References:\n",
        "    [1] He, K., Zhang, X., Ren, S., and Sun, J. (2015b).  Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.\n",
        "    [2] Glorot, X. and Bengio, Y. (2010).  Understanding the difficulty of training deep feedforward neural networks.  \n",
        "    In Teh, Y. W. and Titterington, M., editors, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics,\n",
        "    volume 9 of Proceedings of Machine Learning Research, pages 249–256, Chia Laguna Resort, Sardinia, Italy. PMLR.\n",
        "    \"\"\"\n",
        "    def __init__(self, criterion='he', distribution='uniform', seed=31337):\n",
        "        self.criterion = criterion\n",
        "        self.distribution = distribution\n",
        "        self.seed = seed\n",
        "\n",
        "    def __call__(self, shape, dtype):\n",
        "        fan_in, fan_out = _compute_fans(shape)\n",
        "\n",
        "        if self.criterion == 'he':\n",
        "            std = 1. / np.sqrt(2 * fan_in)\n",
        "        elif self.criterion == 'glorot':\n",
        "            std = 1. / np.sqrt(2 * (fan_in + fan_out))\n",
        "        else:\n",
        "            raise ValueError(\"Chosen criterion was not identified.\")\n",
        "\n",
        "        if self.distribution == 'normal':\n",
        "            return tf.random.normal(shape, mean=0, stddev=std, dtype=dtype, seed=self.seed)\n",
        "        elif self.distribution == 'uniform':\n",
        "            lim = std * np.sqrt(3)\n",
        "            return tf.random.uniform(shape, minval=-lim, maxval=lim, dtype=dtype, seed=self.seed)\n",
        "        else:\n",
        "            raise ValueError(\"Chosen distribution was not identified\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwyY935HA7Nm"
      },
      "source": [
        "class TessConv2D(layers.Layer):\n",
        "    \"\"\"\n",
        "    Tessarine valued 2D convolution layer.\n",
        "    References:\n",
        "    [1] Trabelsi, C., Bilaniuk, O., Serdyuk, D., Subramanian, S., Santos, J. F., Mehri, S., Rostamzadeh, N., Bengio, Y., and Pal, C. J. (2017). Deep complex networks.\n",
        "    [2] Gaudet, C. and Maida, A. (2017). Deep quaternion networks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 filters, \n",
        "                 kernel_size, \n",
        "                 strides=1, \n",
        "                 padding='SAME',\n",
        "                 use_bias=False,\n",
        "                 activation=None,\n",
        "                 initializer=Hypercomplex4DInitializer,\n",
        "                 data_format=None,\n",
        "                 kernel_regularizer=1e-3):\n",
        "        super(TessConv2D, self).__init__()\n",
        "        self.filters = filters \n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activations.get(activation)\n",
        "        self.initializer = initializer\n",
        "        self.data_format = data_format\n",
        "        if kernel_regularizer is not None:\n",
        "            self.kernel_regularizer = kr.regularizers.l2(kernel_regularizer)\n",
        "        else:\n",
        "            self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "    def _get_channel_axis(self):\n",
        "        if self.data_format == 'channels_first':\n",
        "            raise ValueError('TessConv2d is designed only for channels_last. '\n",
        "                             'The input has been changed to channels last!')\n",
        "        else:\n",
        "            return -1\n",
        "    \n",
        "    def _get_input_channel(self, input_shape):\n",
        "        channel_axis = self._get_channel_axis()\n",
        "        if input_shape.dims[channel_axis].value is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        return int(input_shape[channel_axis])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_shape = tensor_shape.TensorShape(input_shape)\n",
        "        input_channel = self._get_input_channel(input_shape)\n",
        "        if input_channel % 4 != 0:\n",
        "            raise ValueError('The number of input channels must be divisible by 4.')\n",
        "    \n",
        "        input_dim = input_channel // 4\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "        \n",
        "        self.f0 = self.add_weight(\n",
        "            name='real_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=self.kernel_regularizer\n",
        "        )\n",
        "        self.f1 = self.add_weight(\n",
        "            name='imag_i_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=self.kernel_regularizer\n",
        "        )\n",
        "        self.f2 = self.add_weight(\n",
        "            name='imag_j_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=self.kernel_regularizer\n",
        "        )\n",
        "        self.f3 = self.add_weight(\n",
        "            name='imag_k_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=self.kernel_regularizer\n",
        "        )\n",
        "        \n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                name='bias',\n",
        "                shape=(4*self.filters,),\n",
        "                initializer=\"zeros\",\n",
        "                trainable=True,\n",
        "                dtype=self.dtype)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def call(self, inputs):\n",
        "        F_r = tf.concat([ self.f0,-self.f1, self.f2,-self.f3],axis=2)\n",
        "        F_i = tf.concat([ self.f1, self.f0, self.f3, self.f2],axis=2)\n",
        "        F_j = tf.concat([ self.f2,-self.f3, self.f0,-self.f1],axis=2)\n",
        "        F_k = tf.concat([ self.f3, self.f2, self.f1, self.f0],axis=2)\n",
        "               \n",
        "        y_r = tf.nn.conv2d(inputs, F_r, strides=self.strides, padding=self.padding)\n",
        "        y_i = tf.nn.conv2d(inputs, F_i, strides=self.strides, padding=self.padding)\n",
        "        y_j = tf.nn.conv2d(inputs, F_j, strides=self.strides, padding=self.padding)\n",
        "        y_k = tf.nn.conv2d(inputs, F_k, strides=self.strides, padding=self.padding)\n",
        "        \n",
        "        outputs = tf.concat([y_r, y_i, y_j, y_k],axis=3)\n",
        "        \n",
        "        if self.use_bias:\n",
        "            outputs = tf.nn.bias_add(outputs,self.bias)\n",
        "            \n",
        "        if self.activation is not None:\n",
        "            outputs = self.activation(outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2GhJfMWD1U"
      },
      "source": [
        "DefaultConvTess = partial(TessConv2D, kernel_size=(3,3), strides=1, padding=\"SAME\", kernel_regularizer=1e-3, use_bias=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWswgBqAs8Xo"
      },
      "source": [
        "def diag_init(shape, dtype=None):\n",
        "    return tf.ones(shape) / 2.\n",
        "\n",
        "class Hypercomplex4DBNActivation(layers.Layer):\n",
        "    \"\"\"\n",
        "    Batch Normalization for tessarines and quaternions.\n",
        "    Based on matrix whitening. Decorrelates each component of tessarine/quaternion.\n",
        "    Includes activation: can be placed before, after or in the middle of BN.\n",
        "    References:\n",
        "    [1] Ioffe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift.\n",
        "    [2] Kessy, A., Lewin, A., and Strimmer, K. (2018). Optimal whitening and decorrelation. The American Statistician, 72(4):309–314.\n",
        "    [3] Trabelsi, C., Bilaniuk, O., Serdyuk, D., Subramanian, S., Santos, J. F., Mehri, S., Ros-tamzadeh, N., Bengio, Y., and Pal, C. J. (2017). Deep complex networks.\n",
        "    [4] Gaudet, C. and Maida, A. (2017). Deep quaternion networks.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 momentum=0.9,\n",
        "                 beta_init='zeros',\n",
        "                 gam_diag_init='diag_init',\n",
        "                 gam_off_init='zeros',\n",
        "                 mov_mean_init='zeros',\n",
        "                 mov_var_init='diag_init',\n",
        "                 mov_cov_init='zeros',\n",
        "                 beta_reg=None,\n",
        "                 gam_diag_reg=None,\n",
        "                 gam_off_reg=None,\n",
        "                 activation=\"elu\",\n",
        "                 activation_position=\"after\",\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(Hypercomplex4DBNActivation, self).__init__(**kwargs)\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.momentum = momentum\n",
        "        self.beta_init = initializers.get(beta_init)\n",
        "\n",
        "        if gam_diag_init == 'diag_init':\n",
        "            self.gam_diag_init = diag_init\n",
        "        else:\n",
        "            self.gam_diag_init = initializers.get(gam_diag_init)\n",
        "\n",
        "        self.gam_off_init = initializers.get(gam_off_init)\n",
        "        self.mov_mean_init = initializers.get(mov_mean_init)\n",
        "\n",
        "        if mov_var_init == 'diag_init':\n",
        "            self.mov_var_init = diag_init\n",
        "        else:    \n",
        "            self.mov_var_init = initializers.get(mov_var_init)\n",
        "            \n",
        "        self.mov_cov_init = initializers.get(mov_cov_init)\n",
        "        self.beta_reg = regularizers.get(beta_reg)\n",
        "        self.gam_diag_reg = regularizers.get(gam_diag_reg)\n",
        "        self.gam_off_reg = regularizers.get(gam_off_reg)\n",
        "        self.activation = activations.get(activation)\n",
        "        self.activation_position = activation_position\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1] // 4\n",
        "        vars_shape = [input_dim, 1]\n",
        "        gamma_shape = (input_dim,)\n",
        "\n",
        "        if self.scale:\n",
        "            self.mov_Vrr = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_var_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vrr\")\n",
        "            self.mov_Vri = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vri\")\n",
        "            self.mov_Vrj = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vrj\")\n",
        "            self.mov_Vrk = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vrk\")\n",
        "            self.mov_Vii = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_var_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vii\")\n",
        "            self.mov_Vij = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vij\")\n",
        "            self.mov_Vik = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vik\")\n",
        "            self.mov_Vjj = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_var_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vjj\")\n",
        "            self.mov_Vjk = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_cov_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vjk\")\n",
        "            self.mov_Vkk = self.add_weight(shape=vars_shape,\n",
        "                                           initializer=self.mov_var_init,\n",
        "                                           trainable=False,\n",
        "                                           name=\"mov_Vkk\")\n",
        "\n",
        "            self.gam_rr = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_diag_init,\n",
        "                                          regularizer=self.gam_diag_reg,\n",
        "                                          name=\"gam_rr\")\n",
        "            self.gam_ri = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_ri\")\n",
        "            self.gam_rj = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_rj\")\n",
        "            self.gam_rk = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_rk\")\n",
        "            self.gam_ii = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_diag_init,\n",
        "                                          regularizer=self.gam_diag_reg,\n",
        "                                          name=\"gam_ii\")\n",
        "            self.gam_ij = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_ij\")\n",
        "            self.gam_ik = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_ik\")\n",
        "            self.gam_jj = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_diag_init,\n",
        "                                          regularizer=self.gam_diag_reg,\n",
        "                                          name=\"gam_jj\")\n",
        "            self.gam_jk = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_off_init,\n",
        "                                          regularizer=self.gam_off_reg,\n",
        "                                          name=\"gam_jk\")\n",
        "            self.gam_kk = self.add_weight(shape=gamma_shape,\n",
        "                                          initializer=self.gam_diag_init,\n",
        "                                          regularizer=self.gam_diag_reg,\n",
        "                                          name=\"gam_kk\")\n",
        "        else:\n",
        "            self.mov_Vrr = None\n",
        "            self.mov_Vri = None\n",
        "            self.mov_Vrj = None\n",
        "            self.mov_Vrk = None\n",
        "            self.mov_Vii = None\n",
        "            self.mov_Vij = None\n",
        "            self.mov_Vik = None\n",
        "            self.mov_Vjj = None\n",
        "            self.mov_Vjk = None\n",
        "            self.mov_Vkk = None\n",
        "            self.gam_rr = None\n",
        "            self.gam_ri = None\n",
        "            self.gam_rj = None\n",
        "            self.gam_rk = None\n",
        "            self.gam_ii = None\n",
        "            self.gam_ij = None\n",
        "            self.gam_ik = None\n",
        "            self.gam_jj = None\n",
        "            self.gam_jk = None\n",
        "            self.gam_kk = None\n",
        "\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=(1, 1, 1, input_shape[-1]),\n",
        "                                        initializer=self.beta_init,\n",
        "                                        regularizer=self.beta_reg,\n",
        "                                        name=\"beta\")\n",
        "            self.mov_mean = self.add_weight(shape=(1, 1, 1, input_shape[-1]),\n",
        "                                            initializer=self.mov_mean_init,\n",
        "                                            trainable=False,\n",
        "                                            name=\"mov_mean\")\n",
        "        else:\n",
        "            self.beta = None\n",
        "            self.mov_mean = None\n",
        "\n",
        "    def _compute_variances(self, centered_r, centered_i, centered_j, centered_k, input_dim):\n",
        "        Vrr = kr.backend.mean(\n",
        "            centered_r ** 2,\n",
        "            axis=[0, 1, 2]\n",
        "        ) + self.epsilon\n",
        "\n",
        "        Vri = kr.backend.mean(\n",
        "            centered_r * centered_i,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vrj = kr.backend.mean(\n",
        "            centered_r * centered_j,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vrk = kr.backend.mean(\n",
        "            centered_r * centered_k,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vii = kr.backend.mean(\n",
        "            centered_i ** 2,\n",
        "            axis=[0, 1, 2]\n",
        "        ) + self.epsilon\n",
        "\n",
        "        Vij = kr.backend.mean(\n",
        "            centered_i * centered_j,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vik = kr.backend.mean(\n",
        "            centered_i * centered_k,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vjj = kr.backend.mean(\n",
        "            centered_j ** 2,\n",
        "            axis=[0, 1, 2]\n",
        "        ) + self.epsilon\n",
        "\n",
        "        Vjk = kr.backend.mean(\n",
        "            centered_j * centered_k,\n",
        "            axis=[0, 1, 2]\n",
        "        )\n",
        "\n",
        "        Vkk = kr.backend.mean(\n",
        "            centered_k ** 2,\n",
        "            axis=[0, 1, 2]\n",
        "        ) + self.epsilon\n",
        "\n",
        "        pars_shape = [input_dim, 1]\n",
        "        Vrr = tf.reshape(Vrr, pars_shape)\n",
        "        Vri = tf.reshape(Vri, pars_shape)\n",
        "        Vrj = tf.reshape(Vrj, pars_shape)\n",
        "        Vrk = tf.reshape(Vrk, pars_shape)\n",
        "        Vii = tf.reshape(Vii, pars_shape)\n",
        "        Vij = tf.reshape(Vij, pars_shape)\n",
        "        Vik = tf.reshape(Vik, pars_shape)\n",
        "        Vjj = tf.reshape(Vjj, pars_shape)\n",
        "        Vjk = tf.reshape(Vjk, pars_shape)\n",
        "        Vkk = tf.reshape(Vkk, pars_shape)\n",
        "\n",
        "        return Vrr, Vri, Vrj, Vrk, Vii, Vij, Vik, Vjj, Vjk, Vkk\n",
        "    \n",
        "    def _moving_exponential_update(self, var, value):\n",
        "        decay = 1 - self.momentum\n",
        "        var.assign_sub(var * decay)\n",
        "        var.assign_add(value * decay)\n",
        "\n",
        "    def _update_moving_parameters(self, mean, Vrr, Vri, Vrj, Vrk, Vii, Vij, Vik, Vjj, Vjk, Vkk):\n",
        "        if self.center:\n",
        "            self._moving_exponential_update(self.mov_mean, mean)\n",
        "\n",
        "        if self.scale:\n",
        "            self._moving_exponential_update(self.mov_Vrr, Vrr)\n",
        "            self._moving_exponential_update(self.mov_Vri, Vri)\n",
        "            self._moving_exponential_update(self.mov_Vrj, Vrj)\n",
        "            self._moving_exponential_update(self.mov_Vrk, Vrk)\n",
        "            self._moving_exponential_update(self.mov_Vii, Vii)\n",
        "            self._moving_exponential_update(self.mov_Vij, Vij)\n",
        "            self._moving_exponential_update(self.mov_Vik, Vik)\n",
        "            self._moving_exponential_update(self.mov_Vjj, Vjj)\n",
        "            self._moving_exponential_update(self.mov_Vjk, Vjk)\n",
        "            self._moving_exponential_update(self.mov_Vkk, Vkk)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if (not self.center) or (not self.scale):\n",
        "            raise ValueError(\"Batch Normalization should scale or center.\")\n",
        "\n",
        "        input_shape = kr.backend.int_shape(inputs)\n",
        "        input_dim = input_shape[-1] // 4\n",
        "\n",
        "        # Activation before\n",
        "        if self.activation_position == \"before\":\n",
        "            output = self.activation(inputs)\n",
        "        else:\n",
        "            output = inputs\n",
        "\n",
        "        if training in {0, False}:\n",
        "            mean = self.mov_mean\n",
        "            centered = output - mean\n",
        "\n",
        "            if self.scale:\n",
        "                centered_r = centered[:, :, :, :input_dim]\n",
        "                centered_i = centered[:, :, :, input_dim:input_dim * 2]\n",
        "                centered_j = centered[:, :, :, input_dim * 2:input_dim * 3]\n",
        "                centered_k = centered[:, :, :, input_dim * 3:]\n",
        "\n",
        "                Vrr = self.mov_Vrr\n",
        "                Vri = self.mov_Vri\n",
        "                Vrj = self.mov_Vrj\n",
        "                Vrk = self.mov_Vrk\n",
        "                Vii = self.mov_Vii\n",
        "                Vij = self.mov_Vij\n",
        "                Vik = self.mov_Vik\n",
        "                Vjj = self.mov_Vjj\n",
        "                Vjk = self.mov_Vjk\n",
        "                Vkk = self.mov_Vkk\n",
        "        else:\n",
        "            # mean and centering\n",
        "            mean = kr.backend.mean(output, axis=[0, 1, 2])\n",
        "            mean = kr.backend.reshape(mean, [1, 1, 1, input_dim * 4])\n",
        "            centered = output - mean\n",
        "\n",
        "            if self.scale:\n",
        "                centered_r = centered[:, :, :, :input_dim]\n",
        "                centered_i = centered[:, :, :, input_dim:input_dim * 2]\n",
        "                centered_j = centered[:, :, :, input_dim * 2:input_dim * 3]\n",
        "                centered_k = centered[:, :, :, input_dim * 3:]\n",
        "\n",
        "                Vrr, Vri, Vrj, Vrk, Vii, Vij, Vik, Vjj, Vjk, Vkk = self._compute_variances(centered_r, centered_i, centered_j, centered_k, input_dim)\n",
        "            else:\n",
        "                Vrr, Vri, Vrj, Vrk, Vii, Vij, Vik, Vjj, Vjk, Vkk = [None for i in range(10)]  \n",
        "\n",
        "            self._update_moving_parameters(mean, Vrr, Vri, Vrj, Vrk, Vii, Vij, Vik, Vjj, Vjk, Vkk)\n",
        "\n",
        "        if self.scale:\n",
        "            var_reshape = [input_dim, 1, 4]\n",
        "            # covariance matrix\n",
        "            V = tf.concat([[tf.reshape(tf.concat([Vrr, Vri, Vrj, Vrk], axis=1), var_reshape)],\n",
        "                           [tf.reshape(tf.concat([Vri, Vii, Vij, Vik], axis=1), var_reshape)],\n",
        "                           [tf.reshape(tf.concat([Vrj, Vij, Vjj, Vjk], axis=1), var_reshape)],\n",
        "                           [tf.reshape(tf.concat([Vrk, Vik, Vjk, Vkk], axis=1), var_reshape)]], axis=2)\n",
        "\n",
        "            # Whitening\n",
        "            R = tf.reshape(tf.linalg.cholesky(V), [input_dim, 4, 4])\n",
        "            W = tf.linalg.inv(tf.transpose(R, perm=[0,2,1]))\n",
        "\n",
        "            Wrr = W[:,0,0]\n",
        "            Wri = W[:,0,1]\n",
        "            Wrj = W[:,0,2]\n",
        "            Wrk = W[:,0,3]\n",
        "            Wii = W[:,1,1]\n",
        "            Wij = W[:,1,2]\n",
        "            Wik = W[:,1,3]\n",
        "            Wjj = W[:,2,2]\n",
        "            Wjk = W[:,2,3]\n",
        "            Wkk = W[:,3,3]\n",
        "\n",
        "            output_r = centered_r * Wrr\n",
        "            output_i = centered_r * Wri + centered_i * Wii\n",
        "            output_j = centered_r * Wrj + centered_i * Wij + centered_j * Wjj\n",
        "            output_k = centered_r * Wrk + centered_i * Wik + centered_j * Wjk + centered_k * Wkk\n",
        "\n",
        "            if self.activation_position == \"middle\":\n",
        "                output_r = self.activation(output_r)\n",
        "                output_i = self.activation(output_i)\n",
        "                output_j = self.activation(output_j)\n",
        "                output_k = self.activation(output_k)\n",
        "\n",
        "            out_r = output_r * self.gam_rr\n",
        "            out_i = output_r * self.gam_ri + output_i * self.gam_ii\n",
        "            out_j = output_r * self.gam_rj + output_i * self.gam_ij + output_j * self.gam_jj\n",
        "            out_k = output_r * self.gam_rk + output_i * self.gam_ik + output_j * self.gam_jk + output_k * self.gam_kk\n",
        "            output = tf.concat([out_r, out_i, out_j, out_k], axis=-1)\n",
        "        else:\n",
        "            output = centered\n",
        "            if self.activation_position == \"middle\":\n",
        "                output = self.activation(output)\n",
        "\n",
        "        if self.center:\n",
        "            output = output + self.beta\n",
        "\n",
        "        if self.activation_position == \"after\":\n",
        "            output = self.activation(output)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69xSlwXXV6TF"
      },
      "source": [
        "class TessResidualUnit(layers.Layer):\n",
        "    \"\"\" \n",
        "    Tessarine valued residual unit.\n",
        "    References:\n",
        "    [1] He, K., Zhang, X., Ren, S., and Sun, J. (2015).  Deep residual learning for image recog-nition.\n",
        "    [2] He, K., Zhang, X., Ren, S., and Sun, J. (2016).  Identity mappings in deep residual net-works.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, strides=1, activation=\"elu\", activation_position='after', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = kr.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConvTess(filters, strides=strides),\n",
        "            Hypercomplex4DBNActivation(activation=activation, activation_position=activation_position),\n",
        "            DefaultConvTess(filters),\n",
        "            Hypercomplex4DBNActivation(activation=activation, activation_position=activation_position)]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConvTess(filters, kernel_size=(1,1), strides=strides),\n",
        "                Hypercomplex4DBNActivation(activation=None, activation_position='no_activation')]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O22ktPu7Xmbs"
      },
      "source": [
        "activation = \"elu\"\n",
        "\n",
        "tess_resnet = kr.models.Sequential()\n",
        "tess_resnet.add(DefaultConvTess(6, kernel_size=(3,3), strides=1))\n",
        "prev_filters = 6\n",
        "for filters in [6] * 3 + [12] * 2 + [24] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    tess_resnet.add(TessResidualUnit(filters, strides=strides, activation=activation))\n",
        "    prev_filters = filters\n",
        "tess_resnet.add(kr.layers.GlobalAvgPool2D())\n",
        "tess_resnet.add(kr.layers.Flatten())\n",
        "tess_resnet.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "tess_resnet.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDSel8db3XEE"
      },
      "source": [
        "Xtr_rgb = np.append(np.zeros([Xtr_cifar.shape[0],32,32,1]),Xtr_cifar,axis=3)\n",
        "Xte_rgb = np.append(np.zeros([Xte_cifar.shape[0],32,32,1]),Xte_cifar,axis=3)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPeKP5t23XBI"
      },
      "source": [
        "datagen = ImageDataGenerator(width_shift_range=0.125, height_shift_range=0.125, horizontal_flip=True)\n",
        "datagen.fit(Xtr_rgb)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DOZO9vmXmY3",
        "outputId": "eb4e3cf0-7ad7-40a6-9a54-17c485cc5720"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "tess_resnet.fit(datagen.flow(Xtr_rgb, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_rgb,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 130s 223ms/step - loss: 2.3526 - accuracy: 0.2971 - val_loss: 2.6545 - val_accuracy: 0.1812\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 83s 211ms/step - loss: 2.1040 - accuracy: 0.3917 - val_loss: 3.5085 - val_accuracy: 0.1574\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 82s 209ms/step - loss: 2.0057 - accuracy: 0.4226 - val_loss: 2.6685 - val_accuracy: 0.2267\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 83s 212ms/step - loss: 1.9146 - accuracy: 0.4571 - val_loss: 2.7493 - val_accuracy: 0.2210\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 81s 208ms/step - loss: 1.8495 - accuracy: 0.4813 - val_loss: 2.7816 - val_accuracy: 0.2397\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 81s 207ms/step - loss: 1.7984 - accuracy: 0.4979 - val_loss: 2.1840 - val_accuracy: 0.3363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9e0236150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzCJcwQ-XmV7",
        "outputId": "1dae1124-5209-4c5b-f3b2-a12a76bdf7a5"
      },
      "source": [
        "tess_resnet.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "tess_conv2d (TessConv2D)     (None, None, None, 24)    216       \n",
            "_________________________________________________________________\n",
            "tess_residual_unit (TessResi (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_1 (TessRe (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_2 (TessRe (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_3 (TessRe (None, None, None, 48)    9072      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_4 (TessRe (None, None, None, 48)    11040     \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_5 (TessRe (None, None, None, 96)    34272     \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_6 (TessRe (None, None, None, 96)    42816     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 107,170\n",
            "Trainable params: 104,146\n",
            "Non-trainable params: 3,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogaLah8Wz6O7"
      },
      "source": [
        "Average time is 82s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ9ZVE36u98K"
      },
      "source": [
        "## Tessarine Valued CNN with Real Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pt45DAZwS97"
      },
      "source": [
        "class TessResidualUnit(layers.Layer):\n",
        "    \"\"\" \n",
        "    Tessarine valued residual unit.\n",
        "    References:\n",
        "    [1] He, K., Zhang, X., Ren, S., and Sun, J. (2015).  Deep residual learning for image recog-nition.\n",
        "    [2] He, K., Zhang, X., Ren, S., and Sun, J. (2016).  Identity mappings in deep residual net-works.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, strides=1, activation=\"elu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = kr.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConvTess(filters, strides=strides),\n",
        "            kr.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            DefaultConvTess(filters),\n",
        "            kr.layers.BatchNormalization(),\n",
        "            self.activation]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConvTess(filters, kernel_size=(1,1), strides=strides),\n",
        "                kr.layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx5Qi08NwS97"
      },
      "source": [
        "activation = \"elu\"\n",
        "\n",
        "tess_resnet = kr.models.Sequential()\n",
        "tess_resnet.add(DefaultConvTess(6, kernel_size=(3,3), strides=1))\n",
        "prev_filters = 6\n",
        "for filters in [6] * 3 + [12] * 2 + [24] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    tess_resnet.add(TessResidualUnit(filters, strides=strides, activation=activation))\n",
        "    prev_filters = filters\n",
        "tess_resnet.add(kr.layers.GlobalAvgPool2D())\n",
        "tess_resnet.add(kr.layers.Flatten())\n",
        "tess_resnet.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "tess_resnet.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXm4C9slwS98",
        "outputId": "10bb4fa2-9d48-4871-fca2-41a0b6af32ad"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "tess_resnet.fit(datagen.flow(Xtr_rgb, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_rgb,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 48s 107ms/step - loss: 2.2484 - accuracy: 0.3346 - val_loss: 3.1941 - val_accuracy: 0.1163\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 2.0429 - accuracy: 0.4113 - val_loss: 2.6683 - val_accuracy: 0.1809\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 1.9506 - accuracy: 0.4484 - val_loss: 2.4716 - val_accuracy: 0.2037\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 39s 100ms/step - loss: 1.8790 - accuracy: 0.4733 - val_loss: 3.3173 - val_accuracy: 0.1238\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 42s 108ms/step - loss: 1.8156 - accuracy: 0.4966 - val_loss: 2.7100 - val_accuracy: 0.2250\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 1.7674 - accuracy: 0.5091 - val_loss: 2.9879 - val_accuracy: 0.1857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe952722110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWe-gg2twS98",
        "outputId": "9b3075e7-ed7e-4059-89ff-738569d0f8ea"
      },
      "source": [
        "tess_resnet.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "tess_conv2d_17 (TessConv2D)  (None, None, None, 24)    216       \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_7 (TessRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_8 (TessRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_9 (TessRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_10 (TessR (None, None, None, 48)    8640      \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_11 (TessR (None, None, None, 48)    10752     \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_12 (TessR (None, None, None, 96)    33408     \n",
            "_________________________________________________________________\n",
            "tess_residual_unit_13 (TessR (None, None, None, 96)    42240     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 104,578\n",
            "Trainable params: 102,850\n",
            "Non-trainable params: 1,728\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbyimAum0DC7"
      },
      "source": [
        "Average time is 41s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reqruvysu9sn"
      },
      "source": [
        "## Quaternion Valued CNN with Hypercomplex Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXtrGw9FxQM4"
      },
      "source": [
        "class QuatConv2D(layers.Layer):\n",
        "    \"\"\"\n",
        "    Quaternion valued 2D convolution layer.\n",
        "    References:\n",
        "    [1] Trabelsi, C., Bilaniuk, O., Serdyuk, D., Subramanian, S., Santos, J. F., Mehri, S., Rostamzadeh, N., Bengio, Y., and Pal, C. J. (2017). Deep complex networks.\n",
        "    [2] Gaudet, C. and Maida, A. (2017). Deep quaternion networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 filters, \n",
        "                 kernel_size, \n",
        "                 strides=1, \n",
        "                 padding='SAME',\n",
        "                 use_bias=False,\n",
        "                 activation=None,\n",
        "                 initializer=Hypercomplex4DInitializer(),\n",
        "                 data_format=None,\n",
        "                 kernel_regularizer=1e-4):\n",
        "        super(QuatConv2D, self).__init__()\n",
        "        self.filters = filters \n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activations.get(activation)\n",
        "        self.initializer = initializer\n",
        "        self.data_format = data_format\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        \n",
        "    def _get_channel_axis(self):\n",
        "        if self.data_format == 'channels_first':\n",
        "            raise ValueError('QuatConv2d is designed only for channels_last. '\n",
        "                             'The input has been changed to channels last!')\n",
        "        else:\n",
        "            return -1\n",
        "    \n",
        "    def _get_input_channel(self, input_shape):\n",
        "        channel_axis = self._get_channel_axis()\n",
        "        if input_shape.dims[channel_axis].value is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                             'should be defined. Found `None`.')\n",
        "        return int(input_shape[channel_axis])\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_shape = tensor_shape.TensorShape(input_shape)\n",
        "        input_channel = self._get_input_channel(input_shape)\n",
        "        if input_channel % 4 != 0:\n",
        "            raise ValueError('The number of input channels must be divisible by 4.')\n",
        "    \n",
        "        input_dim = input_channel // 4\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "        \n",
        "        self.f0 = self.add_weight(\n",
        "            name='real_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=kr.regularizers.l2(self.kernel_regularizer)\n",
        "        )\n",
        "        self.f1 = self.add_weight(\n",
        "            name='imag_i_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=kr.regularizers.l2(self.kernel_regularizer)\n",
        "        )\n",
        "        self.f2 = self.add_weight(\n",
        "            name='imag_j_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=kr.regularizers.l2(self.kernel_regularizer)\n",
        "        )\n",
        "        self.f3 = self.add_weight(\n",
        "            name='imag_k_kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.initializer,\n",
        "            trainable=True,\n",
        "            regularizer=kr.regularizers.l2(self.kernel_regularizer)\n",
        "        )\n",
        "        \n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                name='bias',\n",
        "                shape=(4*self.filters,),\n",
        "                initializer=\"zeros\",\n",
        "                trainable=True,\n",
        "                dtype=self.dtype)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Filter multiplied from the right!\n",
        "        F_r = tf.concat([ self.f0,-self.f1,-self.f2,-self.f3],axis=2)\n",
        "        F_i = tf.concat([ self.f1, self.f0, self.f3,-self.f2],axis=2)\n",
        "        F_j = tf.concat([ self.f2,-self.f3, self.f0, self.f1],axis=2)\n",
        "        F_k = tf.concat([ self.f3, self.f2,-self.f1, self.f0],axis=2)\n",
        "               \n",
        "        y_r = tf.nn.conv2d(inputs, F_r, strides=self.strides, padding=self.padding)\n",
        "        y_i = tf.nn.conv2d(inputs, F_i, strides=self.strides, padding=self.padding)\n",
        "        y_j = tf.nn.conv2d(inputs, F_j, strides=self.strides, padding=self.padding)\n",
        "        y_k = tf.nn.conv2d(inputs, F_k, strides=self.strides, padding=self.padding)\n",
        "        \n",
        "        outputs = tf.concat([y_r, y_i, y_j, y_k],axis=3)\n",
        "        \n",
        "        if self.use_bias:\n",
        "            outputs = tf.nn.bias_add(outputs,self.bias)\n",
        "            \n",
        "        if self.activation is not None:\n",
        "            outputs = self.activation(outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af92o8xoxWkC"
      },
      "source": [
        "DefaultConvQuat = partial(QuatConv2D, kernel_size=(3,3), strides=1, padding=\"SAME\", kernel_regularizer=1e-3, use_bias=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSTRDbjqxYqK"
      },
      "source": [
        "class QuatResidualUnit(layers.Layer):\n",
        "    \"\"\" \n",
        "    Quaternion valued residual unit.\n",
        "    References:\n",
        "    [1] He, K., Zhang, X., Ren, S., and Sun, J. (2015).  Deep residual learning for image recognition.\n",
        "    [2] He, K., Zhang, X., Ren, S., and Sun, J. (2016).  Identity mappings in deep residual networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, strides=1, activation=\"elu\", activation_position=\"after\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = kr.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConvQuat(filters, strides=strides),\n",
        "            Hypercomplex4DBNActivation(activation=activation, activation_position=activation_position), \n",
        "            DefaultConvQuat(filters),\n",
        "            Hypercomplex4DBNActivation(activation=activation, activation_position=activation_position),]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConvQuat(filters, kernel_size=(1,1), strides=strides),\n",
        "                Hypercomplex4DBNActivation(activation=None, activation_position='no_activation')]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLBlJFxRxalX"
      },
      "source": [
        "activation = \"elu\"\n",
        "activation_position = 'after'\n",
        "\n",
        "quat_resnet = kr.models.Sequential()\n",
        "quat_resnet.add(DefaultConvQuat(6, kernel_size=(3,3), strides=1))\n",
        "prev_filters = 6\n",
        "for filters in [6] * 3 + [12] * 2 + [24] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    quat_resnet.add(QuatResidualUnit(filters, strides=strides, activation=activation, activation_position=activation_position))\n",
        "    prev_filters = filters\n",
        "quat_resnet.add(kr.layers.GlobalAvgPool2D())\n",
        "quat_resnet.add(kr.layers.Flatten())\n",
        "quat_resnet.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "quat_resnet.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erZ_kAU5xcXQ",
        "outputId": "32fa2583-dc24-4a88-fa85-3647f41a342b"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "quat_resnet.fit(datagen.flow(Xtr_rgb, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_rgb,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 129s 221ms/step - loss: 2.3633 - accuracy: 0.3007 - val_loss: 2.7681 - val_accuracy: 0.1263\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 84s 214ms/step - loss: 2.1008 - accuracy: 0.3920 - val_loss: 2.9791 - val_accuracy: 0.1319\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 84s 214ms/step - loss: 1.9888 - accuracy: 0.4330 - val_loss: 2.5975 - val_accuracy: 0.2048\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 83s 213ms/step - loss: 1.9063 - accuracy: 0.4610 - val_loss: 3.6654 - val_accuracy: 0.1598\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 83s 212ms/step - loss: 1.8392 - accuracy: 0.4819 - val_loss: 3.4506 - val_accuracy: 0.1258\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 83s 213ms/step - loss: 1.7899 - accuracy: 0.4994 - val_loss: 2.4438 - val_accuracy: 0.2672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe92f2acb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO1DBZ1HxdQr",
        "outputId": "69ceeb8a-e14f-4651-ab29-2bbc93f69dbf"
      },
      "source": [
        "quat_resnet.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quat_conv2d (QuatConv2D)     (None, None, None, 24)    216       \n",
            "_________________________________________________________________\n",
            "quat_residual_unit (QuatResi (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_1 (QuatRe (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_2 (QuatRe (None, None, None, 24)    2928      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_3 (QuatRe (None, None, None, 48)    9072      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_4 (QuatRe (None, None, None, 48)    11040     \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_5 (QuatRe (None, None, None, 96)    34272     \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_6 (QuatRe (None, None, None, 96)    42816     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 107,170\n",
            "Trainable params: 104,146\n",
            "Non-trainable params: 3,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz0QVr0O0E89"
      },
      "source": [
        "Average time is 84s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1APtyt9u9jy"
      },
      "source": [
        "## Quaternion Valued CNN with Real Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AvaHhAHxszi"
      },
      "source": [
        "class QuatResidualUnit(layers.Layer):\n",
        "    \"\"\" \n",
        "    Quaternion valued residual unit.\n",
        "    References:\n",
        "    [1] He, K., Zhang, X., Ren, S., and Sun, J. (2015).  Deep residual learning for image recognition.\n",
        "    [2] He, K., Zhang, X., Ren, S., and Sun, J. (2016).  Identity mappings in deep residual networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, strides=1, activation=\"elu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = kr.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConvQuat(filters, strides=strides),\n",
        "            kr.layers.BatchNormalization(),\n",
        "            self.activation, \n",
        "            DefaultConvQuat(filters),\n",
        "            kr.layers.BatchNormalization(),\n",
        "            self.activation]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConvQuat(filters, kernel_size=(1,1), strides=strides),\n",
        "                kr.layers.BatchNormalization()]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GB8DPeKxszi"
      },
      "source": [
        "activation = \"elu\"\n",
        "\n",
        "quat_resnet = kr.models.Sequential()\n",
        "quat_resnet.add(DefaultConvQuat(6, kernel_size=(3,3), strides=1))\n",
        "prev_filters = 6\n",
        "for filters in [6] * 3 + [12] * 2 + [24] * 2:\n",
        "    strides = 1 if filters == prev_filters else 2\n",
        "    quat_resnet.add(QuatResidualUnit(filters, strides=strides, activation=activation))\n",
        "    prev_filters = filters\n",
        "quat_resnet.add(kr.layers.GlobalAvgPool2D())\n",
        "quat_resnet.add(kr.layers.Flatten())\n",
        "quat_resnet.add(kr.layers.Dense(10, activation=\"softmax\"))\n",
        "quat_resnet.compile(loss=\"categorical_crossentropy\", optimizer=kr.optimizers.SGD(learning_rate=learning_rate(0)), metrics=[\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2E-ZNJbxszi",
        "outputId": "ad10a9ab-5e0f-45d9-9cb7-f006bbfbae54"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 6\n",
        "\n",
        "quat_resnet.fit(datagen.flow(Xtr_rgb, ytr_cifar, batch_size=batch_size), epochs=epochs, validation_data=(Xte_rgb,yte_cifar), callbacks=callbacks)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "391/391 [==============================] - 50s 109ms/step - loss: 2.2526 - accuracy: 0.3358 - val_loss: 2.8217 - val_accuracy: 0.1979\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 39s 100ms/step - loss: 2.0283 - accuracy: 0.4232 - val_loss: 2.5942 - val_accuracy: 0.2465\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 1.9279 - accuracy: 0.4572 - val_loss: 2.7148 - val_accuracy: 0.2334\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 40s 103ms/step - loss: 1.8463 - accuracy: 0.4836 - val_loss: 3.3828 - val_accuracy: 0.1621\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 1.7869 - accuracy: 0.5046 - val_loss: 2.7556 - val_accuracy: 0.2717\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 43s 109ms/step - loss: 1.7324 - accuracy: 0.5238 - val_loss: 2.4137 - val_accuracy: 0.2877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe929175990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWaxuqzZxszi",
        "outputId": "6ec8a4e8-8e91-4d6c-d38e-b04d601f6892"
      },
      "source": [
        "quat_resnet.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quat_conv2d_17 (QuatConv2D)  (None, None, None, 24)    216       \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_7 (QuatRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_8 (QuatRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_9 (QuatRe (None, None, None, 24)    2784      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_10 (QuatR (None, None, None, 48)    8640      \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_11 (QuatR (None, None, None, 48)    10752     \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_12 (QuatR (None, None, None, 96)    33408     \n",
            "_________________________________________________________________\n",
            "quat_residual_unit_13 (QuatR (None, None, None, 96)    42240     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 96)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 104,578\n",
            "Trainable params: 102,850\n",
            "Non-trainable params: 1,728\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYRrfrGp0F_P"
      },
      "source": [
        "Average time is 42s."
      ]
    }
  ]
}